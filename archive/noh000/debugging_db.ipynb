{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a318b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AY\\Desktop\\PROJECTS\\HR-chatbot-development-project\\venv\\Lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "# db.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import threading\n",
    "import time\n",
    "from typing import Tuple, List\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Configuration ---\n",
    "DOCS_DIRECTORY = \".\"\n",
    "HR_DOCUMENT_FILES = [\n",
    "    \"04_ë³µì§€ì •ì±…_v1.0.md\"\n",
    "]\n",
    "# HR_DOCUMENT_FILES = [                 # ë¬¸ì„œ ì¶”ê°€ í›„, ë³€ê²½\n",
    "#     \"01_ì§ì›í•¸ë“œë¶_v1.0_2025-01-10.md\",\n",
    "#     \"02_ê·¼ë¬´ì •ì±…_v1.0.md\",\n",
    "#     \"03_íœ´ê°€ì •ì±…_v1.0.md\",\n",
    "#     \"04_ë³µì§€ì •ì±…_v1.0.md\",\n",
    "#     \"05_ì¥ë¹„Â·ë³´ì•ˆì •ì±…_v1.0.md\",\n",
    "# ]\n",
    "\n",
    "EXISTING_HR_DOCS = [\n",
    "    os.path.join(DOCS_DIRECTORY, f) for f in HR_DOCUMENT_FILES \n",
    "    if os.path.exists(os.path.join(DOCS_DIRECTORY, f))\n",
    "]\n",
    "\n",
    "# --- Caching ---\n",
    "_VSTORE_CACHE = {}\n",
    "_VSTORE_LOCK = threading.Lock()\n",
    "\n",
    "\n",
    "# --- Pinecone Initialization ---\n",
    "def _pc() -> Pinecone:\n",
    "    \"\"\"Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ë°˜í™˜\"\"\"\n",
    "    api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"PINECONE_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return Pinecone(api_key=api_key)\n",
    "\n",
    "def _index_exists(pc: Pinecone, name: str) -> bool:\n",
    "    \"\"\"Pinecone ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "    try:\n",
    "        return name in pc.list_indexes().names()\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"ì¸ë±ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. Fallback ë¡œì§ì„ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "        try:\n",
    "            return name in [idx['name'] for idx in pc.list_indexes()]\n",
    "        except Exception as e_fallback:\n",
    "            logging.error(f\"Fallback ì¸ë±ìŠ¤ ì¡°íšŒë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e_fallback}\")\n",
    "            return False\n",
    "\n",
    "def _ensure_index(pc: Pinecone, name: str, dimension: int) -> None:\n",
    "    \"\"\"Pinecone ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ê³  ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°\"\"\"\n",
    "    if _index_exists(pc, name):\n",
    "        logging.info(f\"Pinecone ì¸ë±ìŠ¤ '{name}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Pinecone ì¸ë±ìŠ¤ '{name}'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "    cloud = os.getenv(\"PINECONE_CLOUD\", \"aws\")\n",
    "    region = os.getenv(\"PINECONE_REGION\", \"us-east-1\")\n",
    "\n",
    "    pc.create_index(\n",
    "        name=name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=cloud, region=region),\n",
    "    )\n",
    "\n",
    "    while not pc.describe_index(name).status['ready']:\n",
    "        logging.info(f\"ì¸ë±ìŠ¤ '{name}' ìƒì„± ëŒ€ê¸° ì¤‘...\")\n",
    "        time.sleep(2)\n",
    "    logging.info(f\"Pinecone ì¸ë±ìŠ¤ '{name}' ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "# --- Document Loading and Splitting ---\n",
    "def _load_and_split_docs(file_paths: List[str]) -> List[Document]:\n",
    "    \"\"\"ì—¬ëŸ¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ë¡œë“œí•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\"\"\"\n",
    "    all_split_docs = []\n",
    "    # HR ë¬¸ì„œ êµ¬ì¡°ì— ë§ëŠ” í—¤ë” ì •ì˜\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"doc_title\"),\n",
    "        (\"##\", \"main_category\"),\n",
    "        (\"###\", \"sub_category\"),\n",
    "    ]\n",
    "    # MarkdownHeaderTextSplitterë¡œ êµ¬ì¡°ì  ë¶„í• \n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on, strip_headers=False\n",
    "    )\n",
    "    # ê¸´ ì„¹ì…˜ì„ ìœ„í•œ ì¶”ê°€ í…ìŠ¤íŠ¸ ë¶„í• \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "            doc_text = loader.load()[0].page_content\n",
    "            \n",
    "            md_header_splits = markdown_splitter.split_text(doc_text)\n",
    "            \n",
    "            for doc in md_header_splits:\n",
    "                doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "\n",
    "            splits = text_splitter.split_documents(md_header_splits)\n",
    "            all_split_docs.extend(splits)\n",
    "            logging.info(f\"'{file_path}' ë¡œë“œ ë° ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬ ìƒì„±.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"'{file_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    return all_split_docs\n",
    "\n",
    "\n",
    "# --- VectorStore ---\n",
    "def get_vectorstore(\n",
    "    index_name: str = \"gaida-hr-rules\",\n",
    "    recreate: bool = False,\n",
    ") -> PineconeVectorStore:\n",
    "    \"\"\"\n",
    "    Pinecone ë²¡í„° ì €ì¥ì†Œë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    - ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    - recreate=Trueì´ë©´, ì¸ë±ìŠ¤ ë‚´ ë¬¸ì„œë¥¼ ëª¨ë‘ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    - DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    cache_key = index_name\n",
    "    with _VSTORE_LOCK:\n",
    "        if not recreate and cache_key in _VSTORE_CACHE:\n",
    "            logging.info(f\"ìºì‹œëœ VectorStore ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤: {cache_key}\")\n",
    "            return _VSTORE_CACHE[cache_key]\n",
    "    \"\"\"\n",
    "    ì„ë² ë”© ëª¨ë¸ë³„ dimension\n",
    "    OpenAI text-embedding-ada-002: 1536\n",
    "    OpenAI text-embedding-3-small: 1536\n",
    "    OpenAI text-embedding-3-large: 3072\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    dimension = 1536\n",
    "\n",
    "    pc = _pc()\n",
    "    _ensure_index(pc, index_name, dimension)\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index=index, embedding=embeddings\n",
    "    )\n",
    "\n",
    "    stats = index.describe_index_stats()\n",
    "    vector_count = stats.get(\"total_vector_count\", 0)\n",
    "\n",
    "    if recreate or vector_count == 0:\n",
    "        if recreate and vector_count > 0:\n",
    "            logging.info(f\"ì¸ë±ìŠ¤ '{index_name}'ì˜ ëª¨ë“  ë²¡í„°({vector_count}ê°œ)ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.\")\n",
    "            index.delete(delete_all=True)\n",
    "        \n",
    "        if EXISTING_HR_DOCS:\n",
    "            logging.info(f\"ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì„ DBì— ì—…ë¡œë“œí•©ë‹ˆë‹¤: {EXISTING_HR_DOCS}\")\n",
    "            split_docs = _load_and_split_docs(EXISTING_HR_DOCS)\n",
    "            if split_docs:\n",
    "                logging.info(f\"ì´ {len(split_docs)}ê°œ ì²­í¬ë¥¼ ì¸ë±ìŠ¤ '{index_name}'ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "                vectorstore.add_documents(documents=split_docs, batch_size=100)\n",
    "        else:\n",
    "            logging.warning(\"ì¡´ì¬í•˜ëŠ” HR ë¬¸ì„œ íŒŒì¼ì´ ì—†ì–´ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        logging.info(f\"ì¸ë±ìŠ¤ '{index_name}'ì— {vector_count}ê°œì˜ ë²¡í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. (ì¬ìƒì„± ì›í•  ì‹œ recreate=True)\")\n",
    "\n",
    "    with _VSTORE_LOCK:\n",
    "        _VSTORE_CACHE[cache_key] = vectorstore\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45400a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes.pyë¡œ ì´ë™\n",
    "def get_retriever(\n",
    "    vectorstore: PineconeVectorStore,\n",
    "    k: int = 5,\n",
    ") -> VectorStoreRetriever:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë²¡í„° ì €ì¥ì†Œì—ì„œ Retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9882172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\04_ë³µì§€ì •ì±…_v1.0.md']\n"
     ]
    }
   ],
   "source": [
    "print(EXISTING_HR_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ee67cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Pinecone ë²¡í„°ìŠ¤í† ì–´ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "í˜„ì¬ ì‹œê°„: 2025-09-24 15:59:07,809\n",
      "ğŸ” Pinecone ë²¡í„°ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "1ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ í™•ì¸\n",
      "âœ… PINECONE_API_KEY: pcsk_FVz...gfz5\n",
      "âœ… OPENAI_API_KEY: sk-proj-...7XAA\n",
      "\n",
      "2ï¸âƒ£ HR ë¬¸ì„œ íŒŒì¼ í™•ì¸\n",
      "âœ… EXISTING_HR_DOCS: ['.\\\\04_ë³µì§€ì •ì±…_v1.0.md']\n",
      "\n",
      "3ï¸âƒ£ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 15:59:15,640 - INFO - Pinecone ì¸ë±ìŠ¤ 'gaida-hr-rules-test'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "2025-09-24 15:59:26,886 - INFO - Pinecone ì¸ë±ìŠ¤ 'gaida-hr-rules-test' ì¤€ë¹„ ì™„ë£Œ.\n",
      "2025-09-24 15:59:28,892 - INFO - ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì„ DBì— ì—…ë¡œë“œí•©ë‹ˆë‹¤: ['.\\\\04_ë³µì§€ì •ì±…_v1.0.md']\n",
      "2025-09-24 15:59:28,917 - INFO - '.\\04_ë³µì§€ì •ì±…_v1.0.md' ë¡œë“œ ë° ë¶„í•  ì™„ë£Œ: 15ê°œ ì²­í¬ ìƒì„±.\n",
      "2025-09-24 15:59:28,924 - INFO - ì´ 15ê°œ ì²­í¬ë¥¼ ì¸ë±ìŠ¤ 'gaida-hr-rules-test'ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n",
      "2025-09-24 15:59:30,339 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì„±ê³µ!\n",
      "\n",
      "4ï¸âƒ£ Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 15:59:34,615 - INFO - ìºì‹œëœ VectorStore ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤: gaida-hr-rules-test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì¸ë±ìŠ¤ í†µê³„:\n",
      "   - ì´ ë²¡í„° ìˆ˜: 0\n",
      "   - ì¸ë±ìŠ¤ í’€ì°¨ì§€: 0.0\n",
      "   - ì°¨ì› ìˆ˜: 1536\n",
      "\n",
      "5ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ë²¡í„° ì—†ìŒ)\n",
      "\n",
      "6ï¸âƒ£ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸\n",
      "   ğŸ“ ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë§Œ ì‚¬ìš© ì¤‘\n",
      "\n",
      "ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "============================================================\n",
      "ğŸ”§ ë²¡í„°ìŠ¤í† ì–´ ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "\n",
      "1ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 15:59:35,428 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: 0\n",
      "2ï¸âƒ£ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 15:59:36,283 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
      "============================================================\n",
      "âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸: ì„±ê³µ\n",
      "âœ… ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸: ì„±ê³µ\n",
      "\n",
      "ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! ë²¡í„°ìŠ¤í† ì–´ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ğŸ—‘ï¸  í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ ì •ë¦¬\n",
      "============================================================\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ 'gaida-hr-rules-test' ì‚­ì œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Pinecone ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "# ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def test_pinecone_vectorstore():\n",
    "    \"\"\"Pinecone ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ìƒíƒœ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” Pinecone ë²¡í„°ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸\n",
    "        print(\"\\n1ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ í™•ì¸\")\n",
    "        api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        if not api_key:\n",
    "            print(\"âŒ PINECONE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return False\n",
    "        if not openai_key:\n",
    "            print(\"âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"âœ… PINECONE_API_KEY: {api_key[:8]}...{api_key[-4:]}\")\n",
    "        print(f\"âœ… OPENAI_API_KEY: {openai_key[:8]}...{openai_key[-4:]}\")\n",
    "        \n",
    "        # 2. íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        print(\"\\n2ï¸âƒ£ HR ë¬¸ì„œ íŒŒì¼ í™•ì¸\")\n",
    "        print(f\"âœ… EXISTING_HR_DOCS: {EXISTING_HR_DOCS}\")\n",
    "        \n",
    "        if not EXISTING_HR_DOCS:\n",
    "            print(\"âš ï¸  ë¬¸ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë²¡í„°ìŠ¤í† ì–´ê°€ ìƒì„±ë©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # 3. ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "        print(\"\\n3ï¸âƒ£ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "        vectorstore = get_vectorstore(\n",
    "            index_name=\"gaida-hr-rules-test\",  # í…ŒìŠ¤íŠ¸ìš© ë³„ë„ ì¸ë±ìŠ¤\n",
    "            recreate=False\n",
    "        )\n",
    "        print(\"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì„±ê³µ!\")\n",
    "        \n",
    "        # 4. Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸\n",
    "        print(\"\\n4ï¸âƒ£ Pinecone ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸\")\n",
    "        pc = _pc()\n",
    "        index = pc.Index(\"gaida-hr-rules-test\")\n",
    "        stats = index.describe_index_stats()\n",
    "        \n",
    "        print(f\"ğŸ“Š ì¸ë±ìŠ¤ í†µê³„:\")\n",
    "        print(f\"   - ì´ ë²¡í„° ìˆ˜: {stats.get('total_vector_count', 0)}\")\n",
    "        print(f\"   - ì¸ë±ìŠ¤ í’€ì°¨ì§€: {stats.get('index_fullness', 0)}\")\n",
    "        print(f\"   - ì°¨ì› ìˆ˜: {stats.get('dimension', 'N/A')}\")\n",
    "        \n",
    "        # 5. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ë²¡í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)\n",
    "        vector_count = stats.get('total_vector_count', 0)\n",
    "        if vector_count > 0:\n",
    "            print(\"\\n5ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "            retriever = get_retriever(vectorstore, k=3)\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
    "            test_queries = [\n",
    "                \"íœ´ê°€ëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?\",\n",
    "                \"ë³µì§€ í˜œíƒì—ëŠ” ë¬´ì—‡ì´ ìˆë‚˜ìš”?\",\n",
    "                \"íšŒì‚¬ ì •ì±…ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    "            ]\n",
    "            \n",
    "            for query in test_queries:\n",
    "                try:\n",
    "                    docs = retriever.get_relevant_documents(query)\n",
    "                    print(f\"\\nğŸ” ì¿¼ë¦¬: '{query}'\")\n",
    "                    print(f\"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "                    \n",
    "                    if docs:\n",
    "                        print(f\"   ì²« ë²ˆì§¸ ë¬¸ì„œ:\")\n",
    "                        print(f\"     - ì¶œì²˜: {docs[0].metadata.get('source', 'N/A')}\")\n",
    "                        print(f\"     - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:100]}...\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        else:\n",
    "            print(\"\\n5ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ë²¡í„° ì—†ìŒ)\")\n",
    "        \n",
    "        # 6. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸ (ìˆëŠ” ê²½ìš°)\n",
    "        print(\"\\n6ï¸âƒ£ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸\")\n",
    "        namespaces = stats.get('namespaces', {})\n",
    "        if namespaces:\n",
    "            for ns_name, ns_stats in namespaces.items():\n",
    "                print(f\"   ğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '{ns_name}': {ns_stats.get('vector_count', 0)}ê°œ ë²¡í„°\")\n",
    "        else:\n",
    "            print(\"   ğŸ“ ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë§Œ ì‚¬ìš© ì¤‘\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        print(f\"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_vectorstore_operations():\n",
    "    \"\"\"ë²¡í„°ìŠ¤í† ì–´ ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ”§ ë²¡í„°ìŠ¤í† ì–´ ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ìš© ì¸ë±ìŠ¤ ìƒì„±\n",
    "        vectorstore = get_vectorstore(\n",
    "            index_name=\"gaida-hr-rules-test\",\n",
    "            recreate=False\n",
    "        )\n",
    "        \n",
    "        # ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "        print(\"\\n1ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "        results = vectorstore.similarity_search(\"íœ´ê°€ ì •ì±…\", k=3)\n",
    "        print(f\"   ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}\")\n",
    "        \n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"   ê²°ê³¼ {i}:\")\n",
    "            print(f\"     ì¶œì²˜: {doc.metadata.get('source', 'N/A')}\")\n",
    "            print(f\"     ë‚´ìš©: {doc.page_content[:150]}...\")\n",
    "            print()\n",
    "        \n",
    "        # ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "        print(\"2ï¸âƒ£ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "        results_with_scores = vectorstore.similarity_search_with_score(\"ì§ì› í˜œíƒ\", k=2)\n",
    "        \n",
    "        for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "            print(f\"   ê²°ê³¼ {i} (ì ìˆ˜: {score:.4f}):\")\n",
    "            print(f\"     ì¶œì²˜: {doc.metadata.get('source', 'N/A')}\")\n",
    "            print(f\"     ë‚´ìš©: {doc.page_content[:100]}...\")\n",
    "            print()\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def cleanup_test_index():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ì¸ë±ìŠ¤ ì‚­ì œ (ì„ íƒì )\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ—‘ï¸  í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ ì •ë¦¬\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        pc = _pc()\n",
    "        test_index_name = \"gaida-hr-rules-test\"\n",
    "        \n",
    "        if _index_exists(pc, test_index_name):\n",
    "            response = input(f\"í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ '{test_index_name}'ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): \")\n",
    "            if response.lower() == 'y':\n",
    "                pc.delete_index(test_index_name)\n",
    "                print(f\"âœ… í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ '{test_index_name}' ì‚­ì œ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(f\"â­ï¸  í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ '{test_index_name}' ìœ ì§€\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸  í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ '{test_index_name}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ========================================\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Pinecone ë²¡í„°ìŠ¤í† ì–´ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"í˜„ì¬ ì‹œê°„:\", logging.Formatter().formatTime(logging.LogRecord(\n",
    "        name=\"test\", level=logging.INFO, pathname=\"\", lineno=0, \n",
    "        msg=\"\", args=(), exc_info=None)))\n",
    "    \n",
    "    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸\n",
    "    success1 = test_pinecone_vectorstore()\n",
    "    \n",
    "    # ì—°ì‚° í…ŒìŠ¤íŠ¸ (ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ ì‹œì—ë§Œ)\n",
    "    success2 = False\n",
    "    if success1:\n",
    "        success2 = test_vectorstore_operations()\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if success1 else 'ì‹¤íŒ¨'}\")\n",
    "    print(f\"âœ… ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if success2 else 'ì‹¤íŒ¨' if success1 else 'ê±´ë„ˆëœ€'}\")\n",
    "    \n",
    "    if success1 and success2:\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! ë²¡í„°ìŠ¤í† ì–´ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    # ì •ë¦¬ ì˜µì…˜ ì œê³µ\n",
    "    cleanup_test_index()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    run_all_tests()\n",
    "    \n",
    "    # ë˜ëŠ” ê°œë³„ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰í•˜ê³  ì‹¶ë‹¤ë©´:\n",
    "    # test_pinecone_vectorstore()\n",
    "    # test_vectorstore_operations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
