{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5c2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def load_hr_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    HR ì •ì±… ë¬¸ì„œë¥¼ TextLoader + MarkdownHeaderTextSplitterë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        List[Document]: ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ë“¤\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. TextLoaderë¡œ ë¬¸ì„œ ë¡œë“œ\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 2. Document ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "    document_text = documents[0].page_content\n",
    "    \n",
    "    # 3. HR ë¬¸ì„œ êµ¬ì¡°ì— ë§ëŠ” í—¤ë” ì •ì˜\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"ë¬¸ì„œì œëª©\"),          # # ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ\n",
    "        (\"##\", \"ì •ì±…ëŒ€ë¶„ë¥˜\"),       # ## 1. íœ´ê°€ ë° íœ´ì§ ì œë„\n",
    "        (\"###\", \"ì •ì±…ì„¸ë¶€í•­ëª©\"),    # ### 1.1 ì—°ì°¨íœ´ê°€\n",
    "        # (\"####\", \"ì„¸ë¶€ì ˆì°¨\"),       # #### **ì‹ ì²­ ì ˆì°¨**\n",
    "    ]\n",
    "    \n",
    "    # 4. MarkdownHeaderTextSplitterë¡œ êµ¬ì¡°ì  ë¶„í• \n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False  # í—¤ë” ì •ë³´ ìœ ì§€ (ì»¨í…ìŠ¤íŠ¸ì— ì¤‘ìš”)\n",
    "    )\n",
    "    \n",
    "    # 5. ë¬¸ìì—´ì„ split_textì— ì „ë‹¬ (Documentê°€ ì•„ë‹Œ str)\n",
    "    md_header_splits = markdown_splitter.split_text(document_text)\n",
    "    \n",
    "    # 6. ê¸´ ì„¹ì…˜ì„ ìœ„í•œ ì¶”ê°€ í…ìŠ¤íŠ¸ ë¶„í• \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # HR Q&Aì— ì í•©í•œ í¬ê¸°\n",
    "        chunk_overlap=200,      # ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ ì˜¤ë²„ë©\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # 7. ìµœì¢… ë¶„í•  ì ìš©\n",
    "    final_splits = text_splitter.split_documents(md_header_splits)\n",
    "    \n",
    "    return final_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS ê±°ë¦¬ ì ìˆ˜ í•´ì„ ê°€ì´ë“œ\n",
    "0.0 - 0.3   # ğŸŸ¢ ë§¤ìš° ìœ ì‚¬ (ê±°ì˜ ë™ì¼í•œ ë‚´ìš©)\n",
    "0.3 - 0.7   # ğŸŸ¡ ì ë‹¹íˆ ìœ ì‚¬ (ê´€ë ¨ì„± ë†’ìŒ)  \n",
    "0.7 - 1.2   # ğŸŸ  ì•½ê°„ ìœ ì‚¬ (ì¼ë¶€ ê´€ë ¨ì„±)\n",
    "1.2 - 2.0   # ğŸ”´ ëœ ìœ ì‚¬ (ê´€ë ¨ì„± ë‚®ìŒ)\n",
    "2.0+        # âš« ê±°ì˜ ë¬´ê´€ (ë‹¤ë¥¸ ì£¼ì œ)\n",
    "\n",
    "# HR ì±—ë´‡ ì¶”ì²œ ì„¤ì •\n",
    "conservative_threshold = 0.8   # ì—„ê²© (ë†’ì€ ì •í™•ë„)\n",
    "balanced_threshold = 1.0       # ê· í˜• (ê¶Œì¥)  \n",
    "lenient_threshold = 1.3        # ê´€ëŒ€ (ë†’ì€ ì¬í˜„ìœ¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddcb1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì‹œì‘...\n",
      "ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: 15ê°œ ì²­í¬\n",
      "âœ… ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì™„ë£Œ (1.13ì´ˆ)\n",
      "ğŸ¯ ìœ ì‚¬ë„ ê²€ìƒ‰ ì •í™•ë„ í‰ê°€ ì‹œì‘...\n",
      "ğŸ“Š ì„¤ì •: k=3, threshold=0.75\n",
      "------------------------------------------------------------\n",
      "[ 1/15] ì—°ì°¨íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 2/15] ë³‘ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 3/15] ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ë°›ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 4/15] êµìœ¡ë¹„ ì§€ì› í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 5/15] ê°œì¸ ì¥ë¹„ êµ¬ì… ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 6/15] ê±´ê°•ê²€ì§„ì€ ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 7/15] ìœ¡ì•„ ì§€ì›ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 8/15] ë™ì•„ë¦¬ í™œë™ë¹„ëŠ” ì–´ë–»ê²Œ ì§€ì›ë˜ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[ 9/15] ê°€ì¡±ëŒë´„íœ´ê°€ëŠ” ìœ ê¸‰ì¸ê°€ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[10/15] íƒœì•„ ê²€ì§„ íœ´ê°€ëŠ” ëª‡ ë²ˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[11/15] ì›”ì°¨ëŠ” ì–¸ì œ ë°›ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[12/15] AKë³µì§€ëª°ì€ ì–´ë–»ê²Œ ê°€ì…í•˜ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[13/15] ì¥ê¸° ê·¼ì†ì ì—°ì°¨ ê°€ì‚°ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[14/15] ìŠ¤ë‚µë°”ì—ëŠ” ë­ê°€ ìˆë‚˜ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "[15/15] ë‚œì„ íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\n",
      "         âŒ MISS | Precision: 0.00 | Retrieved: 0\n",
      "------------------------------------------------------------\n",
      "ğŸ“ˆ ì „ì²´ ê²°ê³¼:\n",
      "   í‰ê·  Precision@3: 0.000\n",
      "   í‰ê·  Hit Rate@3: 0.000\n",
      "   ì„±ê³µí•œ ì¿¼ë¦¬: 0/15\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‹ ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ ì „ì²´ ì„±ëŠ¥ ìš”ì•½\n",
      "   ì´ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 15ê°œ\n",
      "   í‰ê·  Precision@3: 0.000\n",
      "   í‰ê·  Hit Rate@3: 0.000\n",
      "   ê²€ìƒ‰ ì„¤ì •: k=3, threshold=0.75\n",
      "\n",
      "âœ… ì„±ê³µí•œ ì¿¼ë¦¬ (0ê°œ):\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ ì¿¼ë¦¬ (15ê°œ):\n",
      "   â€¢ ì—°ì°¨íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\n",
      "   â€¢ ë³‘ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "   â€¢ ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ë°›ë‚˜ìš”?\n",
      "   â€¢ êµìœ¡ë¹„ ì§€ì› í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\n",
      "   â€¢ ê°œì¸ ì¥ë¹„ êµ¬ì… ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "   â€¢ ê±´ê°•ê²€ì§„ì€ ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "   â€¢ ìœ¡ì•„ ì§€ì›ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "   â€¢ ë™ì•„ë¦¬ í™œë™ë¹„ëŠ” ì–´ë–»ê²Œ ì§€ì›ë˜ë‚˜ìš”?\n",
      "   â€¢ ê°€ì¡±ëŒë´„íœ´ê°€ëŠ” ìœ ê¸‰ì¸ê°€ìš”?\n",
      "   â€¢ íƒœì•„ ê²€ì§„ íœ´ê°€ëŠ” ëª‡ ë²ˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\n",
      "   â€¢ ì›”ì°¨ëŠ” ì–¸ì œ ë°›ë‚˜ìš”?\n",
      "   â€¢ AKë³µì§€ëª°ì€ ì–´ë–»ê²Œ ê°€ì…í•˜ë‚˜ìš”?\n",
      "   â€¢ ì¥ê¸° ê·¼ì†ì ì—°ì°¨ ê°€ì‚°ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "   â€¢ ìŠ¤ë‚µë°”ì—ëŠ” ë­ê°€ ìˆë‚˜ìš”?\n",
      "   â€¢ ë‚œì„ íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\n",
      "\n",
      "ğŸ“Š ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 5ê°œë§Œ í‘œì‹œ):\n",
      "\n",
      "[1] ì¿¼ë¦¬: ì—°ì°¨íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\n",
      "    Precision@3: 0.000 | Hit Rate: False\n",
      "\n",
      "[2] ì¿¼ë¦¬: ë³‘ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "    Precision@3: 0.000 | Hit Rate: False\n",
      "\n",
      "[3] ì¿¼ë¦¬: ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ë°›ë‚˜ìš”?\n",
      "    Precision@3: 0.000 | Hit Rate: False\n",
      "\n",
      "[4] ì¿¼ë¦¬: êµìœ¡ë¹„ ì§€ì› í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\n",
      "    Precision@3: 0.000 | Hit Rate: False\n",
      "\n",
      "[5] ì¿¼ë¦¬: ê°œì¸ ì¥ë¹„ êµ¬ì… ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "    Precision@3: 0.000 | Hit Rate: False\n",
      "\n",
      "ğŸ’¡ ê°œì„  ì œì•ˆ:\n",
      "   â€¢ Precisionì´ ë‚®ìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ 0.80ë¡œ ë†’ì—¬ë³´ì„¸ìš”.\n",
      "   â€¢ Hit Rateê°€ ë‚®ìŠµë‹ˆë‹¤. kê°’ì„ 5ë¡œ ëŠ˜ë¦¬ê±°ë‚˜ ì„ê³„ê°’ì„ 0.70ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "@dataclass\n",
    "class TestQuery:\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì™€ ì˜ˆìƒ ì •ë‹µ ì •ë³´\"\"\"\n",
    "    query: str\n",
    "    expected_sections: List[str]  # ì˜ˆìƒë˜ëŠ” ì •ë‹µ ì„¹ì…˜ í‚¤ì›Œë“œë“¤\n",
    "    description: str\n",
    "\n",
    "@dataclass \n",
    "class SearchResult:\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ ì •ë³´\"\"\"\n",
    "    content: str\n",
    "    score: float\n",
    "    metadata: Dict\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    \"\"\"í‰ê°€ ê²°ê³¼\"\"\"\n",
    "    query: str\n",
    "    precision_at_k: float\n",
    "    hit_rate: bool\n",
    "    retrieved_sections: List[str]\n",
    "    scores: List[float]\n",
    "    is_relevant: List[bool]\n",
    "\n",
    "class HRSimilaritySearchEvaluator:\n",
    "    \"\"\"HR ë¬¸ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ í‰ê°€ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str, k: int = 3, score_threshold: float = 0.75):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path: HR ì •ì±… ë¬¸ì„œ ê²½ë¡œ\n",
    "            k: ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜\n",
    "            score_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’\n",
    "        \"\"\"\n",
    "        load_dotenv()  # .env íŒŒì¼ ë¡œë“œ\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.k = k\n",
    "        self.score_threshold = score_threshold\n",
    "        self.embeddings = None\n",
    "        self.vectorstore = None\n",
    "        self.test_queries = self._create_test_queries()\n",
    "        \n",
    "    def _create_test_queries(self) -> List[TestQuery]:\n",
    "        \"\"\"HR ë¬¸ì„œ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±\"\"\"\n",
    "        return [\n",
    "            TestQuery(\n",
    "                query=\"ì—°ì°¨íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\",\n",
    "                expected_sections=[\"ì—°ì°¨íœ´ê°€\", \"15ì¼\", \"ê¸°ë³¸\"],\n",
    "                description=\"ê¸°ë³¸ ì—°ì°¨ ì¼ìˆ˜ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ë³‘ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ë³‘ê°€\", \"ì‹ ì²­ ì ˆì°¨\", \"ì „ìê²°ì¬\"],\n",
    "                description=\"ë³‘ê°€ ì‹ ì²­ ì ˆì°¨ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ë°›ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ë³µì§€í¬ì¸íŠ¸\", \"300ë§Œì›\", \"ì—°ê°„\"],\n",
    "                description=\"ë³µì§€í¬ì¸íŠ¸ ì§€ê¸‰ì•¡ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"êµìœ¡ë¹„ ì§€ì› í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\",\n",
    "                expected_sections=[\"êµìœ¡ë¹„\", \"50ë§Œì›\", \"ì—°ê°„\"],\n",
    "                description=\"êµìœ¡ë¹„ ì§€ì› í•œë„ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ê°œì¸ ì¥ë¹„ êµ¬ì… ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ê°œì¸ì¥ë¹„\", \"200ë§Œì›\", \"2ë…„\"],\n",
    "                description=\"ê°œì¸ì¥ë¹„ ì§€ì› ì œë„ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ê±´ê°•ê²€ì§„ì€ ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "                expected_sections=[\"ê±´ê°•ê²€ì§„\", \"ë³¸ì¸\", \"ë°°ìš°ì\", \"ë¶€ëª¨\"],\n",
    "                description=\"ê±´ê°•ê²€ì§„ ëŒ€ìƒ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ìœ¡ì•„ ì§€ì›ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?\",\n",
    "                expected_sections=[\"ìœ¡ì•„ ì§€ì›ê¸ˆ\", \"20ë§Œì›\", \"ë§Œ 8ì„¸\"],\n",
    "                description=\"ìœ¡ì•„ ì§€ì›ê¸ˆ ê¸ˆì•¡ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ë™ì•„ë¦¬ í™œë™ë¹„ëŠ” ì–´ë–»ê²Œ ì§€ì›ë˜ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ë™ì•„ë¦¬\", \"2ë§Œì›\", \"1ì¸\", \"1ê°œì›”\"],\n",
    "                description=\"ë™ì•„ë¦¬ í™œë™ë¹„ ì§€ì› ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ê°€ì¡±ëŒë´„íœ´ê°€ëŠ” ìœ ê¸‰ì¸ê°€ìš”?\",\n",
    "                expected_sections=[\"ê°€ì¡±ëŒë´„íœ´ê°€\", \"ë¬´ê¸‰\", \"ì—° 10ì¼\"],\n",
    "                description=\"ê°€ì¡±ëŒë´„íœ´ê°€ ê¸‰ì—¬ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"íƒœì•„ ê²€ì§„ íœ´ê°€ëŠ” ëª‡ ë²ˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "                expected_sections=[\"íƒœì•„ ê²€ì§„\", \"ìœ ê¸‰\", \"ë°˜ì°¨\"],\n",
    "                description=\"íƒœì•„ ê²€ì§„ íœ´ê°€ íšŸìˆ˜ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ì›”ì°¨ëŠ” ì–¸ì œ ë°›ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ì›”ì°¨\", \"1ê°œì›” ë§Œê·¼\", \"ë‹¹í•´ë…„ë„ ì…ì‚¬ì\"],\n",
    "                description=\"ì›”ì°¨ ì§€ê¸‰ ì¡°ê±´ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"AKë³µì§€ëª°ì€ ì–´ë–»ê²Œ ê°€ì…í•˜ë‚˜ìš”?\",\n",
    "                expected_sections=[\"AKë³µì§€ëª°\", \"ê°€ì… ë°©ë²•\", \"íšŒì‚¬ ë©”ì¼\"],\n",
    "                description=\"ë³µì§€ëª° ê°€ì… ë°©ë²• ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ì¥ê¸° ê·¼ì†ì ì—°ì°¨ ê°€ì‚°ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "                expected_sections=[\"ì¥ê¸° ê·¼ì†ì\", \"ê°€ì‚°ì¼\", \"2ë…„ì— 1ì¼\"],\n",
    "                description=\"ì¥ê¸°ê·¼ì† ì—°ì°¨ ê°€ì‚° ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ìŠ¤ë‚µë°”ì—ëŠ” ë­ê°€ ìˆë‚˜ìš”?\",\n",
    "                expected_sections=[\"ìŠ¤ë‚µë°”\", \"ì»¤í”¼ë¨¸ì‹ \", \"ê°„ì‹\", \"ë¬´ë£Œ\"],\n",
    "                description=\"ì‚¬ë‚´ ìŠ¤ë‚µë°” ì‹œì„¤ ë¬¸ì˜\"\n",
    "            ),\n",
    "            TestQuery(\n",
    "                query=\"ë‚œì„ íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\",\n",
    "                expected_sections=[\"ë‚œì„ íœ´ê°€\", \"ì—° 3ì¼\", \"ìœ ê¸‰\"],\n",
    "                description=\"ë‚œì„ íœ´ê°€ ì¼ìˆ˜ ë¬¸ì˜\"\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def setup_vectorstore(self):\n",
    "        \"\"\"ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ë° ë¬¸ì„œ ë¡œë“œ\"\"\"\n",
    "        print(\"ğŸš€ ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì‹œì‘...\")\n",
    "        \n",
    "        # OpenAI API í‚¤ í™•ì¸\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            raise ValueError(\"OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # ë¬¸ì„œ ë¡œë“œ\n",
    "        documents = load_hr_document(self.file_path)\n",
    "        print(f\"ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(documents)}ê°œ ì²­í¬\")\n",
    "        \n",
    "        # FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "        start_time = time.time()\n",
    "        self.vectorstore = FAISS.from_documents(documents, self.embeddings)\n",
    "        setup_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì™„ë£Œ ({setup_time:.2f}ì´ˆ)\")\n",
    "        \n",
    "    def _is_relevant_result(self, query_obj: TestQuery, retrieved_content: str) -> bool:\n",
    "        \"\"\"ê²€ìƒ‰ ê²°ê³¼ê°€ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ íŒë‹¨\"\"\"\n",
    "        content_lower = retrieved_content.lower()\n",
    "        \n",
    "        # ì˜ˆìƒ ì„¹ì…˜ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê´€ë ¨ì„± ìˆìŒ\n",
    "        for section_keyword in query_obj.expected_sections:\n",
    "            if section_keyword.lower() in content_lower:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def search_and_evaluate(self, query_obj: TestQuery) -> EvaluationResult:\n",
    "        \"\"\"ë‹¨ì¼ ì¿¼ë¦¬ì— ëŒ€í•œ ê²€ìƒ‰ ë° í‰ê°€\"\"\"\n",
    "        \n",
    "        # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰\n",
    "        results = self.vectorstore.similarity_search_with_score(\n",
    "            query_obj.query, \n",
    "            k=self.k\n",
    "        )\n",
    "        \n",
    "        # ì„ê³„ê°’ í•„í„°ë§\n",
    "        filtered_results = [\n",
    "            (doc, score) for doc, score in results \n",
    "            if score <= self.score_threshold\n",
    "        ]\n",
    "        \n",
    "        # ê²°ê³¼ ë¶„ì„\n",
    "        retrieved_sections = []\n",
    "        scores = []\n",
    "        is_relevant = []\n",
    "        \n",
    "        for doc, score in filtered_results:\n",
    "            content = doc.page_content\n",
    "            retrieved_sections.append(content[:100] + \"...\" if len(content) > 100 else content)\n",
    "            scores.append(score)\n",
    "            is_relevant.append(self._is_relevant_result(query_obj, content))\n",
    "        \n",
    "        # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "        relevant_count = sum(is_relevant)\n",
    "        total_retrieved = len(filtered_results)\n",
    "        \n",
    "        precision_at_k = relevant_count / total_retrieved if total_retrieved > 0 else 0\n",
    "        hit_rate = relevant_count > 0\n",
    "        \n",
    "        return EvaluationResult(\n",
    "            query=query_obj.query,\n",
    "            precision_at_k=precision_at_k,\n",
    "            hit_rate=hit_rate,\n",
    "            retrieved_sections=retrieved_sections,\n",
    "            scores=scores,\n",
    "            is_relevant=is_relevant\n",
    "        )\n",
    "    \n",
    "    def run_evaluation(self) -> Dict:\n",
    "        \"\"\"ì „ì²´ í‰ê°€ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸ¯ ìœ ì‚¬ë„ ê²€ìƒ‰ ì •í™•ë„ í‰ê°€ ì‹œì‘...\")\n",
    "        print(f\"ğŸ“Š ì„¤ì •: k={self.k}, threshold={self.score_threshold}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        results = []\n",
    "        total_precision = 0\n",
    "        total_hit_rate = 0\n",
    "        \n",
    "        for i, query_obj in enumerate(self.test_queries, 1):\n",
    "            print(f\"[{i:2d}/{len(self.test_queries)}] {query_obj.query}\")\n",
    "            \n",
    "            try:\n",
    "                result = self.search_and_evaluate(query_obj)\n",
    "                results.append(result)\n",
    "                \n",
    "                total_precision += result.precision_at_k\n",
    "                total_hit_rate += int(result.hit_rate)\n",
    "                \n",
    "                # ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œ\n",
    "                status = \"âœ… HIT\" if result.hit_rate else \"âŒ MISS\"\n",
    "                print(f\"         {status} | Precision: {result.precision_at_k:.2f} | Retrieved: {len(result.retrieved_sections)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"         âŒ ERROR: {e}\")\n",
    "                \n",
    "        # ì „ì²´ í†µê³„ ê³„ì‚°\n",
    "        avg_precision = total_precision / len(self.test_queries)\n",
    "        avg_hit_rate = total_hit_rate / len(self.test_queries)\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"ğŸ“ˆ ì „ì²´ ê²°ê³¼:\")\n",
    "        print(f\"   í‰ê·  Precision@{self.k}: {avg_precision:.3f}\")\n",
    "        print(f\"   í‰ê·  Hit Rate@{self.k}: {avg_hit_rate:.3f}\")\n",
    "        print(f\"   ì„±ê³µí•œ ì¿¼ë¦¬: {total_hit_rate}/{len(self.test_queries)}\")\n",
    "        \n",
    "        return {\n",
    "            'results': results,\n",
    "            'avg_precision': avg_precision,\n",
    "            'avg_hit_rate': avg_hit_rate,\n",
    "            'total_queries': len(self.test_queries),\n",
    "            'successful_queries': total_hit_rate\n",
    "        }\n",
    "    \n",
    "    def generate_detailed_report(self, evaluation_results: Dict):\n",
    "        \"\"\"ìƒì„¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ“‹ ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        results = evaluation_results['results']\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ì „ì²´ ì„±ëŠ¥ ìš”ì•½\")\n",
    "        print(f\"   ì´ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {evaluation_results['total_queries']}ê°œ\")\n",
    "        print(f\"   í‰ê·  Precision@{self.k}: {evaluation_results['avg_precision']:.3f}\")\n",
    "        print(f\"   í‰ê·  Hit Rate@{self.k}: {evaluation_results['avg_hit_rate']:.3f}\")\n",
    "        print(f\"   ê²€ìƒ‰ ì„¤ì •: k={self.k}, threshold={self.score_threshold}\")\n",
    "        \n",
    "        # ì„±ê³µ/ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„\n",
    "        successful_queries = [r for r in results if r.hit_rate]\n",
    "        failed_queries = [r for r in results if not r.hit_rate]\n",
    "        \n",
    "        print(f\"\\nâœ… ì„±ê³µí•œ ì¿¼ë¦¬ ({len(successful_queries)}ê°œ):\")\n",
    "        for result in successful_queries:\n",
    "            print(f\"   â€¢ {result.query} (Precision: {result.precision_at_k:.2f})\")\n",
    "        \n",
    "        if failed_queries:\n",
    "            print(f\"\\nâŒ ì‹¤íŒ¨í•œ ì¿¼ë¦¬ ({len(failed_queries)}ê°œ):\")\n",
    "            for result in failed_queries:\n",
    "                print(f\"   â€¢ {result.query}\")\n",
    "                if result.retrieved_sections:\n",
    "                    print(f\"     ê²€ìƒ‰ëœ ë‚´ìš©: {result.retrieved_sections[0][:50]}...\")\n",
    "        \n",
    "        # ìƒì„¸ ê²°ê³¼ (ì„ íƒì  í‘œì‹œ)\n",
    "        print(f\"\\nğŸ“Š ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 5ê°œë§Œ í‘œì‹œ):\")\n",
    "        for i, result in enumerate(results[:5], 1):\n",
    "            print(f\"\\n[{i}] ì¿¼ë¦¬: {result.query}\")\n",
    "            print(f\"    Precision@{self.k}: {result.precision_at_k:.3f} | Hit Rate: {result.hit_rate}\")\n",
    "            \n",
    "            for j, (section, score, relevant) in enumerate(zip(result.retrieved_sections, result.scores, result.is_relevant)):\n",
    "                status = \"âœ…\" if relevant else \"âŒ\"\n",
    "                print(f\"    {j+1}. {status} (Score: {score:.3f}) {section}\")\n",
    "        \n",
    "        # ê°œì„  ì œì•ˆ\n",
    "        print(f\"\\nğŸ’¡ ê°œì„  ì œì•ˆ:\")\n",
    "        if evaluation_results['avg_precision'] < 0.7:\n",
    "            print(f\"   â€¢ Precisionì´ ë‚®ìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ {self.score_threshold + 0.05:.2f}ë¡œ ë†’ì—¬ë³´ì„¸ìš”.\")\n",
    "        if evaluation_results['avg_hit_rate'] < 0.8:\n",
    "            print(f\"   â€¢ Hit Rateê°€ ë‚®ìŠµë‹ˆë‹¤. kê°’ì„ {self.k + 2}ë¡œ ëŠ˜ë¦¬ê±°ë‚˜ ì„ê³„ê°’ì„ {self.score_threshold - 0.05:.2f}ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.\")\n",
    "        if evaluation_results['avg_precision'] > 0.9 and evaluation_results['avg_hit_rate'] > 0.9:\n",
    "            print(f\"   â€¢ ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤! í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    # ì„¤ì •\n",
    "    file_path = \"04_ë³µì§€ì •ì±…_v1.0.md\"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    k = 3\n",
    "    score_threshold = 0.75\n",
    "    \n",
    "    # í‰ê°€ê¸° ì´ˆê¸°í™”\n",
    "    evaluator = HRSimilaritySearchEvaluator(file_path, k, score_threshold)\n",
    "    \n",
    "    try:\n",
    "        # ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •\n",
    "        evaluator.setup_vectorstore()\n",
    "        \n",
    "        # í‰ê°€ ì‹¤í–‰\n",
    "        results = evaluator.run_evaluation()\n",
    "        \n",
    "        # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        evaluator.generate_detailed_report(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        print(\"íŒŒì¼ ê²½ë¡œì™€ í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8be68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a485e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "# ë…¸íŠ¸ë¶ íŒŒì¼ê³¼ ê°™ì€ ìœ„ì¹˜ì— .env íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# .env íŒŒì¼ ë‚´ìš©: OPENAI_API_KEY=\"your_api_key\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f59ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(retriever, test_queries: List[Dict]) -> (float, float, List[Dict]):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    total_hit_rate = 0\n",
    "    results = []\n",
    "\n",
    "    for query_info in test_queries:\n",
    "        query = query_info[\"query\"]\n",
    "        expected_sections = query_info[\"expected_sections\"]\n",
    "        \n",
    "        # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰\n",
    "        retrieved_docs = retriever.invoke(query)\n",
    "        \n",
    "        # ê²€ìƒ‰ëœ ë¬¸ì„œì˜ 'Header 2' ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "        retrieved_sections = [doc.metadata.get('Header 2', 'N/A') for doc in retrieved_docs]\n",
    "        \n",
    "        # Precision@K ê³„ì‚°: ê²€ìƒ‰ëœ Kê°œ ì¤‘ ì •ë‹µì˜ ë¹„ìœ¨\n",
    "        correct_predictions = sum(1 for section in retrieved_sections if section in expected_sections)\n",
    "        precision = correct_predictions / len(retrieved_docs) if retrieved_docs else 0\n",
    "        total_precision += precision\n",
    "        \n",
    "        # Hit Rate@K ê³„ì‚°: ê²€ìƒ‰ëœ Kê°œ ì¤‘ ì •ë‹µì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€\n",
    "        hit = 1 if any(section in expected_sections for section in retrieved_sections) else 0\n",
    "        total_hit_rate += hit\n",
    "        \n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected\": expected_sections,\n",
    "            \"retrieved\": retrieved_sections,\n",
    "            \"precision\": precision,\n",
    "            \"hit\": hit\n",
    "        })\n",
    "        \n",
    "    avg_precision = total_precision / len(test_queries) if test_queries else 0\n",
    "    avg_hit_rate = total_hit_rate / len(test_queries) if test_queries else 0\n",
    "    \n",
    "    return avg_precision, avg_hit_rate, results\n",
    "\n",
    "def generate_report(avg_precision: float, avg_hit_rate: float, results: List[Dict], k: int, threshold: float) -> str:\n",
    "    \"\"\"\n",
    "    í‰ê°€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¦¬í¬íŠ¸ ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(f\"# ê²€ìƒ‰ ì •í™•ë„ í‰ê°€ ë¦¬í¬íŠ¸ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "    report.append(\"\\n## 1. í‰ê°€ ì„¤ì •\")\n",
    "    report.append(f\"- ì„ë² ë”© ëª¨ë¸: `text-embedding-3-small`\")\n",
    "    report.append(f\"- ê²€ìƒ‰ íŒŒë¼ë¯¸í„°: Top-K={k}, ìœ ì‚¬ë„ ì„ê³„ê°’={threshold}\")\n",
    "    \n",
    "    report.append(\"\\n## 2. ì¢…í•© í‰ê°€ ê²°ê³¼\")\n",
    "    report.append(f\"- **Precision@{k}: {avg_precision:.2%}**\")\n",
    "    report.append(f\"- **Hit Rate@{k}: {avg_hit_rate:.2%}**\")\n",
    "    \n",
    "    report.append(\"\\n## 3. ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼\")\n",
    "    for res in results:\n",
    "        report.append(f\"\\n### ì¿¼ë¦¬: \\\"{res['query']}\\\"\")\n",
    "        report.append(f\"- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: {res['expected']}\")\n",
    "        report.append(f\"- **ê²€ìƒ‰ëœ ì„¹ì…˜**: {res['retrieved']}\")\n",
    "        report.append(f\"- **Precision**: {res['precision']:.2f}\")\n",
    "        report.append(f\"- **Hit**: {'Yes' if res['hit'] else 'No'}\")\n",
    "        \n",
    "    return \"\\n\".join(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedd5db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "c:\\Users\\AY\\Desktop\\PROJECTS\\HR-chatbot-development-project\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1070: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='b703f21c-94bc-4f45-9f71-49adc26e0cfd', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ', 'ì •ì±…ì„¸ë¶€í•­ëª©': '2.1 ë³µì§€í¬ì¸íŠ¸'}, page_content='## 2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ  \\n### 2.1 ë³µì§€í¬ì¸íŠ¸\\n- ì—°ê°„ 300ë§Œì›ì˜ ë³µì§€í¬ì¸íŠ¸ê°€ ì§€ê¸‰ë©ë‹ˆë‹¤.\\n- ë‹¹í•´ë…„ë„ ì…ì‚¬ì(1ë…„ ë¯¸ë§Œ ê·¼ì†ì)ëŠ” ê·¼ë¬´ ê°œì›” ìˆ˜ì— ë¹„ë¡€í•˜ì—¬ ì›”í•  ê³„ì‚°í•˜ì—¬ ë‹¹í•´ë¶„ ë³µì§€í¬ì¸íŠ¸ê°€ ì§€ê¸‰ë©ë‹ˆë‹¤. (ì§€ê¸‰ì¼: ìˆ˜ìŠµê¸°ê°„ ì¢…ë£Œì¼)\\n- AKë³µì§€ëª°(https://akfamily.com)ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n- í¬ì¸íŠ¸ëŠ” ë§¤ë…„ 1ì›”ì— ì¼ê´„ ì§€ê¸‰ë©ë‹ˆë‹¤.\\n#### **ê°€ì… ë°©ë²•**\\n1. AKë³µì§€ëª°(https://akfamily.com)ì— ì ‘ì†í•˜ì—¬ íšŒì›ê°€ì… í´ë¦­\\n2. ì†Œì†ì— \"ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤\" ì…ë ¥\\n3. íšŒì‚¬ ë©”ì¼ì£¼ì†Œ ì…ë ¥ í›„ ì´ë©”ì¼ ì¸ì¦\\n#### **ì‹ ì²­ ì ˆì°¨**\\n- ë³„ë„ ì‹ ì²­ ì ˆì°¨ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n- ì‚¬ìš© ë‚´ì—­ì€ AKë³µì§€ëª° ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n---'), np.float32(0.24179387)), (Document(id='bee8c991-3d3e-45a9-ae7f-f8c39aeeddc4', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '4. ì¢…í•© ê±´ê°•ê²€ì§„'}, page_content='## 4. ì¢…í•© ê±´ê°•ê²€ì§„\\n- ì—° 1íšŒ ì¢…í•© ê±´ê°•ê²€ì§„ì„ ì§€ì›í•©ë‹ˆë‹¤.\\n- ì§€ì› ë²”ìœ„: ë³¸ì¸Â·ë°°ìš°ì(ì—° 1íšŒ), ë¶€ëª¨(ë°°ìš°ìì˜ ë¶€ëª¨ í¬í•¨, ì…ì‚¬ë…„ë„ ê¸°ì¤€ 2ë…„ì— 1íšŒ)\\n- ë‹¹í•´ë…„ë„ ì…ì‚¬ì(1ë…„ ë¯¸ë§Œ ê·¼ì†ì)ëŠ” ë‹¤ìŒí•´ë¶€í„° ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤.\\nì˜ˆì‹œ: 2023ë…„ ì…ì‚¬ ì‹œ, 2024ë…„ë¶€í„° ì¢…í•© ê±´ê°•ê²€ì§„ ì´ìš© ê°€ëŠ¥\\n- ì§€ì • ë³‘ì›(í•œêµ­ê±´ê°•ê´€ë¦¬í˜‘íšŒ)ì—ì„œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n- ì „êµ­ ì„¼í„° ì•ˆë‚´: https://www.kahp.or.kr/home/kahp_kor/hlthChk/ntnChkCntrInfo.jsp\\n#### **ì‹ ì²­ ì ˆì°¨**\\n1. ì´ë¬´íŒ€ ì•ˆë‚´ ë©”ì¼ í™•ì¸ (ë§¤ë…„ 1ì›”Â·6ì›”Â·11ì›” ë°œì†¡)\\n2. ì§€ì • ë³‘ì› ì˜ˆì•½ í›„ ì´ìš©\\n---'), np.float32(-0.08444691)), (Document(id='7aca45f6-b3fa-4d2f-9a9a-024ab597e380', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '3. ì—…ë¬´ ì¥ë¹„ ì§€ì›', 'ì •ì±…ì„¸ë¶€í•­ëª©': '3.2 ê°œì¸ì¥ë¹„ ë³´ì¡°'}, page_content='### 3.2 ê°œì¸ì¥ë¹„ ë³´ì¡°\\n- 200ë§Œì›/2ë…„ í•œë„ë¡œ ê°œì¸ ì—…ë¬´ìš© ì¥ë¹„ êµ¬ì…ì„ ê¸°ë³¸ ì¥ë¹„ì™€ ë³„ë„ë¡œ ì¶”ê°€ ì§€ì›í•©ë‹ˆë‹¤.\\n- ì…ì‚¬ì¼ ê¸°ì¤€ìœ¼ë¡œ 2ë…„ë§ˆë‹¤ ê°±ì‹ ë©ë‹ˆë‹¤.\\n- ë‹¹í•´ë…„ë„ ì…ì‚¬ì(1ë…„ ë¯¸ë§Œ ê·¼ì†ì)ëŠ” ìˆ˜ìŠµê¸°ê°„(3ê°œì›”) ì¢…ë£Œ í›„ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n- ì‹ ì²­ ê°€ëŠ¥ ì¥ë¹„: í‚¤ë³´ë“œ, ë§ˆìš°ìŠ¤, íƒœë¸”ë¦¿, í—¤ë“œì…‹\\n- ê·¸ ì™¸ ì¥ë¹„ëŠ” ì´ë¬´íŒ€ì˜ ì‚¬ì „ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n#### **ì‹ ì²­ ì ˆì°¨**\\n1. ì „ìê²°ì œ ì‹œìŠ¤í…œì—ì„œ ê°œì¸ì¥ë¹„ êµ¬ì… ì‹ ì²­ì„œ ì‘ì„±\\n2. ì´ë¬´íŒ€ ìŠ¹ì¸ í›„ êµ¬ë§¤\\n---'), np.float32(-0.12994695))]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "c:\\Users\\AY\\Desktop\\PROJECTS\\HR-chatbot-development-project\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1070: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='a9ec6897-ff16-496c-9c9a-08646db4767d', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '6. ì‚¬ë‚´ ë™ì•„ë¦¬ í™œë™ ì§€ì›'}, page_content='## 6. ì‚¬ë‚´ ë™ì•„ë¦¬ í™œë™ ì§€ì›\\n- ë™ì•„ë¦¬ í™œë™ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì—°ê°„ ì˜ˆì‚°ì´ ì§€ê¸‰ë©ë‹ˆë‹¤. (2ë§Œì›/1ì¸/1ê°œì›”/1ê³³ í•œë„)\\nì˜ˆì‹œ: ë™ì•„ë¦¬ ì¸ì›ì´ 5ëª…ì¼ ê²½ìš°, ì›” 10ë§Œì› ì§€ì›\\n- ì¸ë‹¹ ìµœëŒ€ 2ê³³ê¹Œì§€ í™œë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- ìš´ë™, ê²Œì„, ë…ì„œ, ìŒì•… ë“± ë‹¤ì–‘í•œ í™œë™ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n#### **ì‹ ì²­ ì ˆì°¨**\\n1. Slack #ask-ga ì±„ë„ì—ì„œ ë™ì•„ë¦¬ ê°œì„¤ ì‹ ì²­\\n2. ì´ë¬´íŒ€ ìŠ¹ì¸ í›„ ì˜ˆì‚° ë°°ì •\\n3. í™œë™ë¹„ ì‚¬ìš© í›„ Slack #ask-ga ì±„ë„ì— ì˜ìˆ˜ì¦ ì œì¶œ\\n4. ë‹¤ìŒë‹¬ ê¸‰ì—¬ì— ë°˜ì˜\\n---'), np.float32(0.071034074)), (Document(id='7aca45f6-b3fa-4d2f-9a9a-024ab597e380', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '3. ì—…ë¬´ ì¥ë¹„ ì§€ì›', 'ì •ì±…ì„¸ë¶€í•­ëª©': '3.2 ê°œì¸ì¥ë¹„ ë³´ì¡°'}, page_content='### 3.2 ê°œì¸ì¥ë¹„ ë³´ì¡°\\n- 200ë§Œì›/2ë…„ í•œë„ë¡œ ê°œì¸ ì—…ë¬´ìš© ì¥ë¹„ êµ¬ì…ì„ ê¸°ë³¸ ì¥ë¹„ì™€ ë³„ë„ë¡œ ì¶”ê°€ ì§€ì›í•©ë‹ˆë‹¤.\\n- ì…ì‚¬ì¼ ê¸°ì¤€ìœ¼ë¡œ 2ë…„ë§ˆë‹¤ ê°±ì‹ ë©ë‹ˆë‹¤.\\n- ë‹¹í•´ë…„ë„ ì…ì‚¬ì(1ë…„ ë¯¸ë§Œ ê·¼ì†ì)ëŠ” ìˆ˜ìŠµê¸°ê°„(3ê°œì›”) ì¢…ë£Œ í›„ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n- ì‹ ì²­ ê°€ëŠ¥ ì¥ë¹„: í‚¤ë³´ë“œ, ë§ˆìš°ìŠ¤, íƒœë¸”ë¦¿, í—¤ë“œì…‹\\n- ê·¸ ì™¸ ì¥ë¹„ëŠ” ì´ë¬´íŒ€ì˜ ì‚¬ì „ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n#### **ì‹ ì²­ ì ˆì°¨**\\n1. ì „ìê²°ì œ ì‹œìŠ¤í…œì—ì„œ ê°œì¸ì¥ë¹„ êµ¬ì… ì‹ ì²­ì„œ ì‘ì„±\\n2. ì´ë¬´íŒ€ ìŠ¹ì¸ í›„ êµ¬ë§¤\\n---'), np.float32(-0.1496216)), (Document(id='d3878aa2-eee3-4bdb-a529-8b333c3b1330', metadata={'ë¬¸ì„œì œëª©': 'ê°€ì´ë‹¤ í”Œë ˆì´ ìŠ¤íŠœë””ì˜¤(GPS) ì§ì› ë³µì§€ì œë„ ì¢…í•© ì•ˆë‚´ì„œ', 'ì •ì±…ëŒ€ë¶„ë¥˜': '1. íœ´ê°€ ë° íœ´ì§ ì œë„', 'ì •ì±…ì„¸ë¶€í•­ëª©': '1.3 ê°€ì¡±ëŒë´„íœ´ê°€'}, page_content='### 1.3 ê°€ì¡±ëŒë´„íœ´ê°€\\n- ë²•ì • ê¸°ì¤€ì— ë”°ë¼ ì—° 10ì¼ ë¬´ê¸‰ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- ìë…€, ë¶€ëª¨(ë°°ìš°ìì˜ ë¶€ëª¨ í¬í•¨), ë°°ìš°ìì˜ ì§ˆë³‘Â·ì‚¬ê³ Â·ë…¸ë ¹ ëŒë´„ ì‚¬ìœ ì— í•œí•©ë‹ˆë‹¤.\\n#### **ì‹ ì²­ ì ˆì°¨**\\n1. ì „ìê²°ì¬(íŒ€ì¥) ìŠ¹ì¸ í›„ íœ´ê°€ í™•ì •\\n2. ì „ìê²°ì¬ ìŠ¹ì¸ ì‹œ ìë™ìœ¼ë¡œ Google Calendarì™€ ì—°ë™ë˜ì–´ íŒ€ì›ë“¤ê³¼ ê³µìœ \\n3. ì „ìê²°ì œ ì‹œìŠ¤í…œì—ì„œ ê°€ì¡±ëŒë´„íœ´ê°€ ì‹ ì²­ì„œ ì‘ì„± (ì œì¶œê¸°í•œ: ê°€ì¡±ëŒë´„íœ´ê°€ ë‹¹ì¼ê¹Œì§€)\\n4. ì¸ì‚¬íŒ€ ìŠ¹ì¸ í›„ ê¸‰ì—¬ì— ë°˜ì˜\\n---'), np.float32(-0.1719997))]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‰ê°€ ì™„ë£Œ! 'retrieval_evaluation_report_20250922_210059.md' íŒŒì¼ì— ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# ê²€ìƒ‰ ì •í™•ë„ í‰ê°€ ë¦¬í¬íŠ¸ (2025-09-22 21:00:59)\n",
       "\n",
       "## 1. í‰ê°€ ì„¤ì •\n",
       "- ì„ë² ë”© ëª¨ë¸: `text-embedding-3-small`\n",
       "- ê²€ìƒ‰ íŒŒë¼ë¯¸í„°: Top-K=3, ìœ ì‚¬ë„ ì„ê³„ê°’=0.5\n",
       "\n",
       "## 2. ì¢…í•© í‰ê°€ ê²°ê³¼\n",
       "- **Precision@3: 0.00%**\n",
       "- **Hit Rate@3: 0.00%**\n",
       "\n",
       "## 3. ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼\n",
       "\n",
       "### ì¿¼ë¦¬: \"ì—°ì°¨ëŠ” ë©°ì¹  ì£¼ë‚˜ìš”?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['1. íœ´ê°€ ë° íœ´ì§ ì œë„']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ë³‘ê°€ ì‚¬ìš©ë²• ì•Œë ¤ì¤˜\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['1. íœ´ê°€ ë° íœ´ì§ ì œë„']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆì•¼?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"êµìœ¡ë¹„ ì§€ì› ë°›ì„ ìˆ˜ ìˆì–´?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ë…¸íŠ¸ë¶ ë§ê³  ê°œì¸ ì¥ë¹„ë„ ì‚¬ì£¼ë‚˜ìš”?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['3. ì—…ë¬´ ì¥ë¹„ ì§€ì›']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ê±´ê°•ê²€ì§„ì€ ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆì–´?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['4. ì¢…í•© ê±´ê°•ê²€ì§„']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ë™ì•„ë¦¬ ë§Œë“¤ê³  ì‹¶ì–´\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['6. ì‚¬ë‚´ ë™ì•„ë¦¬ í™œë™ ì§€ì›']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No\n",
       "\n",
       "### ì¿¼ë¦¬: \"ìœ¡ì•„ ì§€ì›ê¸ˆ ì‹ ì²­ ì–´ë–»ê²Œ í•´?\"\n",
       "- **ì˜ˆìƒ ì •ë‹µ ì„¹ì…˜**: ['7. ì„ì‹ Â·ì¶œì‚°Â·ìœ¡ì•„ ì§€ì›']\n",
       "- **ê²€ìƒ‰ëœ ì„¹ì…˜**: []\n",
       "- **Precision**: 0.00\n",
       "- **Hit**: No"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- í‰ê°€ ì‹¤í–‰ ---\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ (ë…¸íŠ¸ë¶ì— ì´ë¯¸ ì •ì˜ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "# íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "file_path = \"04_ë³µì§€ì •ì±…_v1.0.md\"\n",
    "docs = load_hr_document(file_path)\n",
    "\n",
    "# 2. ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 3. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "K = 3\n",
    "SCORE_THRESHOLD = 0.5\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'k': K, 'score_threshold': SCORE_THRESHOLD}\n",
    ")\n",
    "\n",
    "# 4. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ë° ì˜ˆìƒ ì •ë‹µ ì •ì˜\n",
    "# 'expected_sections'ëŠ” load_hr_document í•¨ìˆ˜ê°€ ìƒì„±í•˜ëŠ” ë©”íƒ€ë°ì´í„°('Header 2')ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "test_queries = [\n",
    "    {\"query\": \"ì—°ì°¨ëŠ” ë©°ì¹  ì£¼ë‚˜ìš”?\", \"expected_sections\": [\"1. íœ´ê°€ ë° íœ´ì§ ì œë„\"]},\n",
    "    {\"query\": \"ë³‘ê°€ ì‚¬ìš©ë²• ì•Œë ¤ì¤˜\", \"expected_sections\": [\"1. íœ´ê°€ ë° íœ´ì§ ì œë„\"]},\n",
    "    {\"query\": \"ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆì•¼?\", \"expected_sections\": [\"2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ\"]},\n",
    "    {\"query\": \"êµìœ¡ë¹„ ì§€ì› ë°›ì„ ìˆ˜ ìˆì–´?\", \"expected_sections\": [\"2. ë³µì§€í¬ì¸íŠ¸ ë° ì§€ì›ê¸ˆ\"]},\n",
    "    {\"query\": \"ë…¸íŠ¸ë¶ ë§ê³  ê°œì¸ ì¥ë¹„ë„ ì‚¬ì£¼ë‚˜ìš”?\", \"expected_sections\": [\"3. ì—…ë¬´ ì¥ë¹„ ì§€ì›\"]},\n",
    "    {\"query\": \"ê±´ê°•ê²€ì§„ì€ ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆì–´?\", \"expected_sections\": [\"4. ì¢…í•© ê±´ê°•ê²€ì§„\"]},\n",
    "    {\"query\": \"ë™ì•„ë¦¬ ë§Œë“¤ê³  ì‹¶ì–´\", \"expected_sections\": [\"6. ì‚¬ë‚´ ë™ì•„ë¦¬ í™œë™ ì§€ì›\"]},\n",
    "    {\"query\": \"ìœ¡ì•„ ì§€ì›ê¸ˆ ì‹ ì²­ ì–´ë–»ê²Œ í•´?\", \"expected_sections\": [\"7. ì„ì‹ Â·ì¶œì‚°Â·ìœ¡ì•„ ì§€ì›\"]},\n",
    "]\n",
    "\n",
    "# 5. í‰ê°€ ì‹¤í–‰\n",
    "avg_precision, avg_hit_rate, results = evaluate_retrieval(retriever, test_queries)\n",
    "\n",
    "# 6. ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥\n",
    "report_content = generate_report(avg_precision, avg_hit_rate, results, K, SCORE_THRESHOLD)\n",
    "\n",
    "report_filename = f\"retrieval_evaluation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_content)\n",
    "    \n",
    "print(f\"í‰ê°€ ì™„ë£Œ! '{report_filename}' íŒŒì¼ì— ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"\\n--- ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° ---\")\n",
    "# ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œëŠ” Markdownì„ ë” ì˜ˆì˜ê²Œ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(report_content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
