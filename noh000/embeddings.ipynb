{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4c9dcc",
   "metadata": {},
   "source": [
    "# 로더 테스트\n",
    "- 04_복지정책_v1.0.md 기준  \n",
    "TextLoader: 0.0285초  \n",
    "UnstructuredMarkdownLoader: 18.1923초  \n",
    "성능 차이: 637.5배"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "def performance_test(file_path: str):\n",
    "    # TextLoader 테스트\n",
    "    start = time.time()\n",
    "    text_loader = TextLoader(file_path, encoding=\"UTF-8\")\n",
    "    text_docs = text_loader.load()\n",
    "    text_time = time.time() - start\n",
    "    print(f\"TextLoader: {text_time:.4f}초\")\n",
    "    \n",
    "    # UnstructuredMarkdownLoader 테스트\n",
    "    start = time.time()\n",
    "    unstructured_loader = UnstructuredMarkdownLoader(\n",
    "        file_path, \n",
    "        mode=\"elements\",\n",
    "        strategy=\"fast\"\n",
    "    )\n",
    "    unstructured_docs = unstructured_loader.load()\n",
    "    unstructured_time = time.time() - start\n",
    "    print(f\"UnstructuredMarkdownLoader: {unstructured_time:.4f}초\")\n",
    "    \n",
    "    print(f\"성능 차이: {unstructured_time/text_time:.1f}배\")\n",
    "\n",
    "file_path = \"./04_복지정책_v1.0.md\"\n",
    "performance_test(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580611ac",
   "metadata": {},
   "source": [
    "# TextLoader + 헤더 기반 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def load_hr_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    HR 정책 문서를 TextLoader + MarkdownHeaderTextSplitter로 로드하는 함수\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 마크다운 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "        List[Document]: 분할된 문서 청크들\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. TextLoader로 문서 로드\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 2. Document 객체에서 텍스트 내용 추출\n",
    "    document_text = documents[0].page_content\n",
    "    \n",
    "    # 3. HR 문서 구조에 맞는 헤더 정의\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"문서제목\"),          # # 가이다 플레이 스튜디오(GPS) 직원 복지제도 종합 안내서\n",
    "        (\"##\", \"정책대분류\"),       # ## 1. 휴가 및 휴직 제도\n",
    "        (\"###\", \"정책세부항목\"),    # ### 1.1 연차휴가\n",
    "        # (\"####\", \"세부절차\"),       # #### **신청 절차**\n",
    "    ]\n",
    "    \n",
    "    # 4. MarkdownHeaderTextSplitter로 구조적 분할\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False  # 헤더 정보 유지 (컨텍스트에 중요)\n",
    "    )\n",
    "    \n",
    "    # 5. 문자열을 split_text에 전달 (Document가 아닌 str)\n",
    "    md_header_splits = markdown_splitter.split_text(document_text)\n",
    "    \n",
    "    # 6. 긴 섹션을 위한 추가 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # HR Q&A에 적합한 크기\n",
    "        chunk_overlap=200,      # 충분한 컨텍스트 오버랩\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # 7. 최종 분할 적용\n",
    "    final_splits = text_splitter.split_documents(md_header_splits)\n",
    "    \n",
    "    return final_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38200590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복지정책 적용\n",
    "file_path = \"./04_복지정책_v1.0.md\"\n",
    "splits = load_hr_document(file_path)\n",
    "\n",
    "len_splits = len(splits)\n",
    "print(f\"✅ 로딩 성공! 총 {len_splits}개 청크로 분할됨\")\n",
    "print(\"=\"*100)\n",
    "for i in range(len_splits):\n",
    "    print(f\"메타데이터: {splits[i].metadata}\")\n",
    "    print(f\"내용: {splits[i].page_content[:200]}...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677f4b8",
   "metadata": {},
   "source": [
    "# 임베딩 모델 비교\n",
    "- OpenAI text-embedding-3-small\n",
    "- BAAI/bge-m3\n",
    "- intfloat/multilingual-e5-large-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d847ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치 검증 스크립트\n",
    "try:\n",
    "    import langchain\n",
    "    import langchain_openai\n",
    "    import langchain_community\n",
    "    import openai\n",
    "    import sentence_transformers\n",
    "    import transformers\n",
    "    import faiss\n",
    "    import torch\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    print(\"✅ 모든 패키지 설치 완료!\")\n",
    "    print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "    print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ 패키지 설치 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec086fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# .env 파일에서 API 키 로드\n",
    "load_dotenv()\n",
    "\n",
    "def get_hr_test_queries() -> List[str]:\n",
    "    \"\"\"\n",
    "    HR 문서 관련 테스트 쿼리 반환\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"연차휴가는 몇 일인가요?\",\n",
    "        \"복지포인트는 어떻게 사용하나요?\",\n",
    "        \"교육비 지원 신청 방법을 알려주세요\",\n",
    "        \"육아 지원금은 얼마나 받을 수 있나요?\",\n",
    "        \"건강검진은 언제부터 받을 수 있나요?\",\n",
    "        \"장기 근속자 가산일 규정\",\n",
    "        \"병가 사용 시 필요한 서류\",\n",
    "        \"동아리 활동비 지원 한도\"\n",
    "    ]\n",
    "\n",
    "def test_search_performance(vector_store: FAISS, model_name: str, test_queries: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    단일 모델의 검색 성능 테스트\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 {model_name} 검색 성능 테스트\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    model_results = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n질문 {i}: {query}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # 유사도 검색 (상위 3개 결과)\n",
    "        search_results = vector_store.similarity_search(query, k=3)\n",
    "        search_time = time.time() - start_time\n",
    "        total_time += search_time\n",
    "        \n",
    "        print(f\"⏱️  검색 시간: {search_time:.3f}초\")\n",
    "        print(\"📋 검색 결과:\")\n",
    "        \n",
    "        query_result = {\n",
    "            \"query\": query,\n",
    "            \"search_time\": search_time,\n",
    "            \"results\": []\n",
    "        }\n",
    "        \n",
    "        for j, doc in enumerate(search_results, 1):\n",
    "            # 결과 미리보기 (처음 100자)\n",
    "            preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "            print(f\"  {j}. {preview}...\")\n",
    "            \n",
    "            query_result[\"results\"].append({\n",
    "                \"rank\": j,\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            })\n",
    "        \n",
    "        model_results.append(query_result)\n",
    "    \n",
    "    result = {\n",
    "        \"model_name\": model_name,\n",
    "        \"total_time\": total_time,\n",
    "        \"avg_time\": total_time / len(test_queries),\n",
    "        \"queries\": model_results\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n📊 {model_name} 전체 성능:\")\n",
    "    print(f\"  총 검색 시간: {total_time:.3f}초\")\n",
    "    print(f\"  평균 검색 시간: {total_time/len(test_queries):.3f}초\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_openai_embedding(documents: List[Document], test_queries: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    OpenAI text-embedding-3-small 테스트\n",
    "    \"\"\"\n",
    "    model_name = \"OpenAI text-embedding-3-small\"\n",
    "    print(f\"\\n🚀 {model_name} 테스트 시작\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 임베딩 모델 로드\n",
    "        print(\"📥 임베딩 모델 로드 중...\")\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        print(\"✅ OpenAI 임베딩 로드 완료\")\n",
    "        \n",
    "        # 2. 벡터스토어 생성\n",
    "        print(\"🔄 벡터스토어 생성 중...\")\n",
    "        start_time = time.time()\n",
    "        vector_store = FAISS.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        creation_time = time.time() - start_time\n",
    "        print(f\"✅ 벡터스토어 생성 완료 ({creation_time:.2f}초)\")\n",
    "        \n",
    "        # 3. 검색 성능 테스트\n",
    "        result = test_search_performance(vector_store, model_name, test_queries)\n",
    "        result[\"creation_time\"] = creation_time\n",
    "        \n",
    "        # 4. 메모리 정리\n",
    "        del vector_store, embeddings\n",
    "        gc.collect()\n",
    "        print(f\"🧹 {model_name} 메모리 정리 완료\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {model_name} 테스트 실패: {e}\")\n",
    "        return {\"model_name\": model_name, \"error\": str(e)}\n",
    "\n",
    "def test_bge_m3_embedding(documents: List[Document], test_queries: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    BAAI/bge-m3 테스트\n",
    "    \"\"\"\n",
    "    model_name = \"BAAI/bge-m3\"\n",
    "    print(f\"\\n🚀 {model_name} 테스트 시작\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 임베딩 모델 로드\n",
    "        print(\"📥 임베딩 모델 로드 중...\")\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"BAAI/bge-m3\",\n",
    "            model_kwargs={'device': 'cpu'},  # GPU 사용시 'cuda'로 변경\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        print(\"✅ BGE-M3 임베딩 로드 완료\")\n",
    "        \n",
    "        # 2. 벡터스토어 생성\n",
    "        print(\"🔄 벡터스토어 생성 중...\")\n",
    "        start_time = time.time()\n",
    "        vector_store = FAISS.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        creation_time = time.time() - start_time\n",
    "        print(f\"✅ 벡터스토어 생성 완료 ({creation_time:.2f}초)\")\n",
    "        \n",
    "        # 3. 검색 성능 테스트\n",
    "        result = test_search_performance(vector_store, model_name, test_queries)\n",
    "        result[\"creation_time\"] = creation_time\n",
    "        \n",
    "        # 4. 메모리 정리\n",
    "        del vector_store, embeddings\n",
    "        gc.collect()\n",
    "        print(f\"🧹 {model_name} 메모리 정리 완료\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {model_name} 테스트 실패: {e}\")\n",
    "        return {\"model_name\": model_name, \"error\": str(e)}\n",
    "\n",
    "def test_e5_large_embedding(documents: List[Document], test_queries: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    intfloat/multilingual-e5-large-instruct 테스트\n",
    "    \"\"\"\n",
    "    model_name = \"multilingual-e5-large-instruct\"\n",
    "    print(f\"\\n🚀 {model_name} 테스트 시작\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 임베딩 모델 로드\n",
    "        print(\"📥 임베딩 모델 로드 중...\")\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "            model_kwargs={'device': 'cpu'},  # GPU 사용시 'cuda'로 변경\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        print(\"✅ E5-Large 임베딩 로드 완료\")\n",
    "        \n",
    "        # 2. 벡터스토어 생성\n",
    "        print(\"🔄 벡터스토어 생성 중...\")\n",
    "        start_time = time.time()\n",
    "        vector_store = FAISS.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        creation_time = time.time() - start_time\n",
    "        print(f\"✅ 벡터스토어 생성 완료 ({creation_time:.2f}초)\")\n",
    "        \n",
    "        # 3. 검색 성능 테스트\n",
    "        result = test_search_performance(vector_store, model_name, test_queries)\n",
    "        result[\"creation_time\"] = creation_time\n",
    "        \n",
    "        # 4. 메모리 정리\n",
    "        del vector_store, embeddings\n",
    "        gc.collect()\n",
    "        print(f\"🧹 {model_name} 메모리 정리 완료\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {model_name} 테스트 실패: {e}\")\n",
    "        return {\"model_name\": model_name, \"error\": str(e)}\n",
    "\n",
    "def compare_all_models(documents: List[Document]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    모든 모델을 순차적으로 테스트하고 결과 비교\n",
    "    \"\"\"\n",
    "    print(\"🚀 임베딩 모델 순차 비교 테스트 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_queries = get_hr_test_queries()\n",
    "    results = []\n",
    "    \n",
    "    # 각 모델을 순차적으로 테스트 (메모리 절약)\n",
    "    print(f\"\\n📋 {len(test_queries)}개 테스트 쿼리 준비 완료\")\n",
    "    \n",
    "    # 1. OpenAI 테스트\n",
    "    openai_result = test_openai_embedding(documents, test_queries)\n",
    "    results.append(openai_result)\n",
    "    \n",
    "    # 2. BGE-M3 테스트  \n",
    "    bge_result = test_bge_m3_embedding(documents, test_queries)\n",
    "    results.append(bge_result)\n",
    "    \n",
    "    # 3. E5-Large 테스트\n",
    "    e5_result = test_e5_large_embedding(documents, test_queries)\n",
    "    results.append(e5_result)\n",
    "    \n",
    "    # 4. 결과 비교\n",
    "    print_comparison_summary(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_single_model(documents: List[Document], model_choice: str) -> Dict:\n",
    "    \"\"\"\n",
    "    단일 모델만 테스트 (메모리 제약이 심할 때)\n",
    "    \n",
    "    Args:\n",
    "        documents: HR 문서 청크들\n",
    "        model_choice: 'openai', 'bge', 'e5' 중 선택\n",
    "    \"\"\"\n",
    "    test_queries = get_hr_test_queries()\n",
    "    \n",
    "    if model_choice.lower() == 'openai':\n",
    "        return test_openai_embedding(documents, test_queries)\n",
    "    elif model_choice.lower() == 'bge':\n",
    "        return test_bge_m3_embedding(documents, test_queries)\n",
    "    elif model_choice.lower() == 'e5':\n",
    "        return test_e5_large_embedding(documents, test_queries)\n",
    "    else:\n",
    "        raise ValueError(\"model_choice는 'openai', 'bge', 'e5' 중 하나여야 합니다.\")\n",
    "\n",
    "def print_comparison_summary(results: List[Dict]):\n",
    "    \"\"\"\n",
    "    모델별 성능 비교 요약 출력\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🏆 임베딩 모델 성능 비교 요약\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 성공한 모델들만 필터링\n",
    "    valid_results = [r for r in results if \"error\" not in r]\n",
    "    \n",
    "    if not valid_results:\n",
    "        print(\"❌ 성공한 테스트가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 성능 데이터 준비\n",
    "    performance_data = []\n",
    "    for result in valid_results:\n",
    "        performance_data.append({\n",
    "            \"모델\": result[\"model_name\"],\n",
    "            \"벡터스토어 생성\": f\"{result.get('creation_time', 0):.2f}초\",\n",
    "            \"평균 검색 시간\": f\"{result['avg_time']:.3f}초\",\n",
    "            \"총 검색 시간\": f\"{result['total_time']:.3f}초\"\n",
    "        })\n",
    "    \n",
    "    # 검색 속도순 정렬\n",
    "    performance_data.sort(key=lambda x: float(x[\"평균 검색 시간\"].replace(\"초\", \"\")))\n",
    "    \n",
    "    print(\"\\n📊 성능 순위 (빠른 순):\")\n",
    "    for i, data in enumerate(performance_data, 1):\n",
    "        print(f\"  {i}. {data['모델']}\")\n",
    "        print(f\"     벡터스토어 생성: {data['벡터스토어 생성']}\")\n",
    "        print(f\"     평균 검색 시간: {data['평균 검색 시간']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"💡 MVP 개발 권장사항:\")\n",
    "    if performance_data:\n",
    "        fastest_model = performance_data[0][\"모델\"]\n",
    "        print(f\"  • 검색 속도 1위: {fastest_model}\")\n",
    "        print(f\"  • 10일 MVP 개발용 추천: {fastest_model}\")\n",
    "        print(f\"  • Pinecone 연동 시 이 모델 사용 권장\")\n",
    "    \n",
    "    # 에러 발생한 모델들 표시\n",
    "    error_results = [r for r in results if \"error\" in r]\n",
    "    if error_results:\n",
    "        print(\"\\n⚠️  테스트 실패한 모델:\")\n",
    "        for result in error_results:\n",
    "            print(f\"  • {result['model_name']}: {result['error']}\")\n",
    "\n",
    "# 사용 예시 함수들\n",
    "def quick_test_all(documents: List[Document]):\n",
    "    \"\"\"\n",
    "    빠른 전체 모델 테스트 (추천)\n",
    "    \"\"\"\n",
    "    return compare_all_models(documents)\n",
    "\n",
    "def quick_test_one(documents: List[Document], model: str):\n",
    "    \"\"\"\n",
    "    단일 모델 빠른 테스트\n",
    "    \"\"\"\n",
    "    return test_single_model(documents, model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔧 임베딩 모델 비교 테스트 도구\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"사용법:\")\n",
    "    print(\"1. 전체 모델 테스트: quick_test_all(documents)\")\n",
    "    print(\"2. 단일 모델 테스트: quick_test_one(documents, 'openai')\")\n",
    "    print(\"3. 개별 함수 호출:\")\n",
    "    print(\"   - test_openai_embedding(documents, queries)\")\n",
    "    print(\"   - test_bge_m3_embedding(documents, queries)\")  \n",
    "    print(\"   - test_e5_large_embedding(documents, queries)\")\n",
    "    \n",
    "    # 실제 사용 예시:\n",
    "    # documents = load_hr_policy_document(\"04_복지정책_v1.0.md\")\n",
    "    # results = quick_test_all(documents)\n",
    "    # 또는\n",
    "    # result = quick_test_one(documents, 'openai')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
