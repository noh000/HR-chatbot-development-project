{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d1eddb",
   "metadata": {},
   "source": [
    "## env 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7697bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c72bba",
   "metadata": {},
   "source": [
    "## state 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing_extensions import Any\n",
    "\n",
    "class State(MessagesState):\n",
    "    question: str  # 사용자 질문\n",
    "    dataset: Any   # 임의의 데이터셋(추후엔 DB에서 가져오거나 해야함)\n",
    "    status: bool   # (라우터) ex. db에서 해당 정보를 찾을 수 있는지 없는지\n",
    "    result: str    # DB에서 받은 결과\n",
    "    answer: str    # 최종 답변```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614976e2",
   "metadata": {},
   "source": [
    "## llm, Search 클래스(TypedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1342a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import TypedDict, List\n",
    "from typing import Literal  # 말그대로\n",
    "from typing_extensions import Annotated  # 할말이 좀 더 있다\n",
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "# State를 더 빡빡하게 정의하기 위해, 위에 따로 정의한 클래스 Search\n",
    "\n",
    "class Search(TypedDict):  # StructuredOutput 에서 사용하기 위함.\n",
    "    \"\"\"Vectorstore Search Query\"\"\"\n",
    "    # 1. 타입, 2. ... -> NOT NULL, 3. 설명(AI용)\n",
    "    query: Annotated[str, ..., 'Search query to run']\n",
    "    section: Annotated[\n",
    "        Literal[work, leave, equipment, welfare, etc],\n",
    "        ..., \n",
    "        'Section to query'\n",
    "    ]\n",
    "\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbda6d",
   "metadata": {},
   "source": [
    "## analyze_query 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(state: MyState):\n",
    "    # Search 클래스에 맞춰 사용자 question 을 {query, section}로 바꿈\n",
    "    s_llm = llm.with_structured_output(Search)\n",
    "    query = s_llm.invoke(state['question'])\n",
    "    return {'query': query}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a533e4",
   "metadata": {},
   "source": [
    "## DB(문서) 불러오기 → 임베딩 → Pinecone 색인 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b04382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer  # pip install beautifulsoup4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"데이터셋.md\", encoding=\"utf-8\")  # 또는 autodetect_encoding=True\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "\n",
    "for i, doc in enumerate(splitted_docs):\n",
    "    content = doc.page_content.lower()\n",
    "    \n",
    "    if any(keyword in content for keyword in [\"근무\", \"출근\", \"업무\", \"근로\"]):\n",
    "        doc.metadata['category'] = 'work'\n",
    "    elif any(keyword in content for keyword in [\"휴가\", \"연차\", \"병가\", \"휴직\"]):\n",
    "        doc.metadata['category'] = 'leave'\n",
    "    elif any(keyword in content for keyword in [\"장비\", \"보안\", \"시설\", \"컴퓨터\"]):\n",
    "        doc.metadata['category'] = 'equipment'\n",
    "    elif any(keyword in content for keyword in [\"복지\", \"혜택\", \"지원\", \"보험\"]):\n",
    "        doc.metadata['category'] = 'welfare' \n",
    "    else:\n",
    "        doc.metadata['category'] = 'etc'\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')  # small <-> large\n",
    "\n",
    "index_name = 'gaida 회사 내규'\n",
    "\n",
    "# 1회 실행하면, 실제 데이터가 들어가서 영구 저장 됨.\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    splitted_docs, \n",
    "    index_name=index_name, \n",
    "    embedding=embedding\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860cc59",
   "metadata": {},
   "source": [
    "## retrieve 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a43cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query\n",
    "    Args:\n",
    "        query : Query to search\n",
    "    \"\"\"\n",
    "    # 원본 Document list (artifact)\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    # 편집한 텍스트 (content)\n",
    "    result_text = '\\n\\n'.join(\n",
    "        (f'Source: {doc.metadata}\\nContent: {doc.page_content}')\n",
    "        for doc in docs\n",
    "    )\n",
    "    return result_text, docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
